{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to ML Methods in Atomistic Modelling\n",
    "\n",
    "These notebooks provide a hands-on introduction to linear and kernel methods, with applications to chemical and materials modelling. The notebooks provide a rather complete discussion of the theoretical foundations of supervised and unsupervised learning techniques, starting from principal component analysis and linear regression, and continuing to rather advanced techniques based on the kernel trick. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Dataset\n",
    "A dataset composed of molecular materials extracted from the Cambridge Structural Database, and optimized at the DFT-PBE level is used as a demonstrative example. For each atom, the nuclear magnetic shielding has been computed with the GIPAW method, and so exercises aim to reveal the relation between local chemical environments and the value of the [chemical shielding](https://en.wikipedia.org/wiki/Chemical_shift). Both \"local\" and \"total\" chemical shieldings (that also contain terms related to the macroscopic magnetism of the material) are included, to demonstrate the simultaneous description of multiple properties. The two properties are nearly identical, and we include them just to show how regression methods can be applied to multiple properties at once.\n",
    "\n",
    "**Note**: for pedagogic purposes, all chemical elements are considered together, even though from an applicative (and physical) point of view it does not make sense to compare shielding values for different elements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The atom-centred environments are represented in terms of 2 and 3-body correlations, described by the [SOAP](https://doi.org/10.1063/1.5090481) power spectrum, and can be computed using the `librascal` library, following the procedure in  [Importing Data](X_ImportingData.ipynb). For ease of use, pre-computed features can be downloaded from [here](https://www.dropbox.com/s/itokckbbkvxaqsk/precomputed.npz?dl=0). The file `precomputed.npz` should be copied to the `datasets/` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Use These Notebooks\n",
    "\n",
    "Notebooks are meant to be read and executed sequentially, and should function without the need of writing any code. However, for best learning outcomes, more Python-savvy readers are encouraged to experiment with modifying the code, printing and visualizing intermediate values, or even just changing the input files to correspond to a different chemical system. The package also contains a set of utility functions that can be used to perform analyses using a scikit-learn-style syntax, that are demonstrated at the end of each notebook, and that are used when demonstrating the behavior of different methods when their hyperparameters are changed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `LinearMethods` delves into linear regression (LR), principal component analysis (PCA), and multidimensional scaling (MDS).\n",
    "\n",
    "2. `PrincipalCovariatesRegression` demonstrates a method, PCovR, which combines the power of unsupervised (PCA) and supervised (LR) learning.\n",
    "\n",
    "3. In `KernelMethods`, we introduce versions of the previous models which take advantage of the **kernel trick**.\n",
    "\n",
    "4. In  `SparseKernelMethods`, we demonstrate methods which use the kernel trick, but with lower computational cost, working with few samples.\n",
    "\n",
    "5. In `CUR`, we explain a matrix decomposition strategy to approximate input data or select features for ML models, and extend this method using PCovR.\n",
    "\n",
    "* There are also a few appendices, denoted `X_Appendix.ipynb`, which contain information on importing data and the notation used throughout the tutorial.\n",
    "\n",
    "These notebooks have the following dependencies: `ase`, `json`, `matplotlib`, `numpy`, `scipy`, `sklearn`, and `tqdm`. We also suggest to enable the Jupyter Notebook `Python Markdown` extension.\n",
    "\n",
    "Furthermore, many new methods require the v0.1 release of the `scikit-cosmo` package, which can be downloaded from pip or via <https://github.com/cosmo-epfl/scikit-cosmo>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "210px",
    "width": "289px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "186.914px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
